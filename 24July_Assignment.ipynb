{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3becaa42",
   "metadata": {},
   "source": [
    "1.Create a table attribute dataset and dress dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as conn\n",
    "mydb = conn.connect(host=\"localhost\", user=\"root\", password=\"pass\")\n",
    "print(mydb)\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "cursor.execute('''CREATE TABLE rakmo.attribute_dataset (\n",
    "  `Dress_ID` int DEFAULT NULL,\n",
    "  `Style` text,\n",
    "  `Price` text,\n",
    "  `Rating` double DEFAULT NULL,\n",
    "  `Size` text,\n",
    "  `Season` text,\n",
    "  `NeckLine` text,\n",
    "  `SleeveLength` text,\n",
    "  `waiseline` text,\n",
    "  `Material` text,\n",
    "  `FabricType` text,\n",
    "  `Decoration` text,\n",
    "  `Pattern Type` text,\n",
    "  `Recommendation` int DEFAULT NULL);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE rakmo.dress_sales (\n",
    "  `Dress_ID` int DEFAULT NULL,\n",
    "  `29/8/2013` int DEFAULT NULL,\n",
    "  `31/8/2013` int DEFAULT NULL,\n",
    "  `2/9/2013` int DEFAULT NULL,\n",
    "  `4/9/2013` int DEFAULT NULL,\n",
    "  `6/9/2013` int DEFAULT NULL,\n",
    "  `8/9/2013` int DEFAULT NULL,\n",
    "  `10/9/2013` int DEFAULT NULL,\n",
    "  `12/9/2013` int DEFAULT NULL,\n",
    "  `14/9/2013` int DEFAULT NULL,\n",
    "  `16/9/2013` int DEFAULT NULL,\n",
    "  `18/9/2013` int DEFAULT NULL,\n",
    "  `20/9/2013` int DEFAULT NULL,\n",
    "  `22/9/2013` int DEFAULT NULL,\n",
    "  `24/9/2013` int DEFAULT NULL,\n",
    "  `26/9/2013` int DEFAULT NULL,\n",
    "  `28/9/2013` int DEFAULT NULL,\n",
    "  `30/9/2013` int DEFAULT NULL,\n",
    "  `2/10/2013` int DEFAULT NULL,\n",
    "  `4/10/2013` int DEFAULT NULL,\n",
    "  `6/10/2013` int DEFAULT NULL,\n",
    "  `8/10/2010` int DEFAULT NULL,\n",
    "  `10/10/2013` int DEFAULT NULL,\n",
    "  `12/10/2013` int DEFAULT NULL,\n",
    "  `MyUnknownColumn` text,\n",
    "  `MyUnknownColumn_[0]` text,\n",
    "  `MyUnknownColumn_[1]` text,\n",
    "  `MyUnknownColumn_[2]` text,\n",
    "  `MyUnknownColumn_[3]` text,\n",
    "  `MyUnknownColumn_[4]` text,\n",
    "  `MyUnknownColumn_[5]` text,\n",
    "  `MyUnknownColumn_[6]` text,\n",
    "  `MyUnknownColumn_[7]` text,\n",
    "  `MyUnknownColumn_[8]` text,\n",
    "  `MyUnknownColumn_[9]` text,\n",
    "  `MyUnknownColumn_[10]` text\n",
    ");''')\n",
    "\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4515e9",
   "metadata": {},
   "source": [
    "2.Do a bulk load for these two table for respective dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e6c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector as mysql\n",
    "from mysql.connector import Error\n",
    "\n",
    "a=pd.read_csv(r'C:\\Users\\omth0419\\Desktop\\data fsds\\data fsds_\\Attribute DataSet.csv', index_col=None)\n",
    "a = a.fillna('')\n",
    "\n",
    "try:\n",
    "    conn = mysql.connect(host=\"localhost\", user=\"root\", password=\"pass\", database=\"ineuron\")\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "        #loop through the data frame\n",
    "        for i,row in a.iterrows():\n",
    "            sql = \"INSERT INTO ineuron.attribute_dataset VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "            cursor.execute(sql, tuple(row))\n",
    "#            print(\"Record inserted\")\n",
    "#            conn.commit()\n",
    "        conn.commit()\n",
    "        print(\"Records have been inserted\")\n",
    "except Error as e:\n",
    "            print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f728830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector as mysql\n",
    "from mysql.connector import Error\n",
    "\n",
    "a=pd.read_csv(r'C:\\Users\\omth0419\\Desktop\\data fsds\\data fsds_\\Dress Sales.csv', index_col=None)\n",
    "df1 = a.where(pd.notnull(a), 0)\n",
    "df1.where(pd.convert())\n",
    "df1 = df1.fillna('')\n",
    "\n",
    "try:\n",
    "    conn = mysql.connect(host=\"localhost\", user=\"root\", password=\"pass\", database=\"ineuron\")\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "        #loop through the data frame\n",
    "        for i,row in df1.iterrows():\n",
    "            sql = \"INSERT INTO ineuron.dress_sales VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "            cursor.execute(sql, tuple(row))\n",
    "            print(\"Record inserted\")\n",
    "            conn.commit()\n",
    "#        conn.commit()\n",
    "#        print(\"Records have been inserted\")\n",
    "except Error as e:\n",
    "            print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608fe2e",
   "metadata": {},
   "source": [
    "3.read these dataset in pandas as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:pass@localhost:3306/rakmo')\n",
    "a = pd.read_sql_table('dress_sales',engine)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:pass@localhost:3306/rakmo')\n",
    "a = pd.read_sql_table('attribute_dataset',engine)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4300e3",
   "metadata": {},
   "source": [
    "4.Convert attribute dataset in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:pass@localhost:3306/rakmo')\n",
    "a = pd.read_sql_table('attribute_dataset',engine)\n",
    "a.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66752657",
   "metadata": {},
   "source": [
    "5.Store this dataset into mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a440908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "import mysql.connector as conn\n",
    "mydb = conn.connect(host=\"localhost\", user=\"root\", password=\"pass\")\n",
    "\n",
    "mycursor = mydb.cursor(dictionary=True) \n",
    "mycursor.execute(\"SELECT * from ineuron.attribute_dataset;\") \n",
    "myresult = mycursor.fetchall() \n",
    "#print(myresult)\n",
    "\n",
    "#engine = sqlalchemy.create_engine('mysql+pymysql://root:logan786@localhost:3306/ineuron')\n",
    "#a = pd.read_sql_table('attribute_dataset',engine)\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://logan:logan786@cluster0.d07rw.mongodb.net/?retryWrites=true&w=majority\")\n",
    "\n",
    "db = client.test\n",
    "#print(db)\n",
    "\n",
    "#data1 = a.to_json()\n",
    "#type(data1)\n",
    "db = client['mongodb']\n",
    "coll = database['atribute_dataset']\n",
    "#coll.insert_one(data1)\n",
    "#coll.insert_many([data1])\n",
    "\n",
    "if len(myresult) > 0:\n",
    "        x = coll.insert_many(myresult) #myresult comes from mysql cursor\n",
    "        print(len(x.inserted_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265ca81",
   "metadata": {},
   "source": [
    "6.in sql task try to perform left join operation with attrubute dataset and dress dataset on column Dress_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:pass@localhost:3306/ineuron')\n",
    "#pd.read_sql_table('dress_sales',engine)\n",
    "\n",
    "query = '''\n",
    "SELECT *\n",
    " FROM attribute_dataset LEFT JOIN dress_sales\n",
    " ON attribute_dataset.Dress_ID=dress_sales.Dress_ID\n",
    "'''\n",
    "\n",
    "pd.read_sql_query(query,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c8814",
   "metadata": {},
   "source": [
    "7.Write a sql query to find out how many unique dress that we have based on dress id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:pass@localhost:3306/ineuron')\n",
    "#pd.read_sql_table('dress_sales',engine)\n",
    "\n",
    "query = '''\n",
    "select count(*) from dress_sales inner join attribute_dataset on \n",
    "dress_sales.dress_id=attribute_dataset.dress_id;\n",
    "'''\n",
    "\n",
    "pd.read_sql_query(query,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf7882",
   "metadata": {},
   "source": [
    "8.Try to find out how mnay dress is having recommendation 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064b055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:pass@localhost:3306/ineuron')\n",
    "#pd.read_sql_table('dress_sales',engine)\n",
    "\n",
    "query = '''\n",
    " SELECT count(*) as Recommendation_0\n",
    " FROM attribute_dataset\n",
    " where Recommendation=0;\n",
    "'''\n",
    "\n",
    "pd.read_sql_query(query,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81168fd",
   "metadata": {},
   "source": [
    "9.Try to find out total dress sell for individual dress id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:pass@localhost:3306/ineuron')\n",
    "#pd.read_sql_table('dress_sales',engine)\n",
    "\n",
    "query = '''select dress_id,Sum(`29/8/2013`+`31/8/2013`+`2/9/2013`+`4/9/2013`+`6/9/2013`+`8/9/2013`+\n",
    "`10/9/2013`+`12/9/2013`+`14/9/2013`+`16/9/2013`+`18/9/2013`+`20/9/2013`+`22/9/2013`+`24/9/2013`+\n",
    "`26/9/2013`+`28/9/2013`+`30/9/2013`+`2/10/2013`+`4/10/2013`+`6/10/2013`+`8/10/2010`+`10/10/2013`+`12/10/2013`) as Total_sales \n",
    "from dress_sales\n",
    "group by dress_id\n",
    "order by Total_sales desc;\n",
    "'''\n",
    "\n",
    "pd.read_sql_query(query,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ad639",
   "metadata": {},
   "source": [
    "10.Try to find out a third highest most selling dress id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50061601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:pass@localhost:3306/ineuron')\n",
    "#pd.read_sql_table('dress_sales',engine)\n",
    "\n",
    "query = '''select dress_id,Sum(`29/8/2013`+`31/8/2013`+`2/9/2013`+`4/9/2013`+`6/9/2013`+`8/9/2013`+\n",
    "`10/9/2013`+`12/9/2013`+`14/9/2013`+`16/9/2013`+`18/9/2013`+`20/9/2013`+`22/9/2013`+`24/9/2013`+\n",
    "`26/9/2013`+`28/9/2013`+`30/9/2013`+`2/10/2013`+`4/10/2013`+`6/10/2013`+`8/10/2010`+`10/10/2013`+`12/10/2013`) as Total_sales \n",
    "from dress_sales\n",
    "group by dress_id\n",
    "order by Total_sales desc limit 1 offset 2;\n",
    "'''\n",
    "\n",
    "pd.read_sql_query(query,engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
